{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61449e58-ad43-40e0-8e09-65cae2cbd074",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scikit-learn version 1.3.0 is not supported. Minimum required version: 0.17. Maximum required version: 1.1.2. Disabling scikit-learn conversion API.\n"
     ]
    }
   ],
   "source": [
    "import torch, matplotlib as mpl\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch import tensor\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import coremltools as ct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed6d61a-2973-46bb-b076-ba25e37b20ce",
   "metadata": {},
   "source": [
    "### Configure GPU acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fa28d33-90a9-43e0-b039-b58887ea459f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "# cuda: NVIDIA GPUs, mps: Metal Performance Shaders (Apple M GPUs), cpu: generic CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37862f4d-ed65-4196-8591-92ae3d028d0b",
   "metadata": {},
   "source": [
    "### Import MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69999be2-7021-4f2c-aa6b-ea4d1c9662e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('./MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=10000, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.MNIST('./MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=10000, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a294a219-9d80-4234-9ee4-4d48e69146b6",
   "metadata": {},
   "source": [
    "#### Create tensors for training and testing from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8a66505-4fb9-40da-a421-70a58e372fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 1, 28, 28])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train = next(iter(trainloader))\n",
    "x_test, y_test = next(iter(testloader))\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3976511e-e81b-43f8-bfca-06e28779ccb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 784])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = x_train.view(10000,-1)\n",
    "x_test = x_test.view(10000,-1)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a6e12a5-9e51-4914-80a4-a9c9f7850622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(y_train[500])\n",
    "xsq = x_train.reshape((-1,28,28)).to(torch.device(\"cpu\"))\n",
    "_ = plt.imshow(xsq[500].view(28,28), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31df1451-c1bc-46ab-be55-5a0674ddf314",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3aff1b-a366-48eb-9450-2f323a825150",
   "metadata": {},
   "source": [
    "### Configure network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b41d9a9-2293-49f6-9244-8527b5290468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (sigmoid): ReLU()\n",
      "  (Dense1): Linear(in_features=784, out_features=80, bias=True)\n",
      "  (Dense2): Linear(in_features=80, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.0125, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# construct the model\n",
    "nin = x_train.shape[1]\n",
    "nout = int(np.max(y_train.numpy())+1)\n",
    "\n",
    "# Create Net class\n",
    "# nin: dimension of input data\n",
    "# nout: number of outputs\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,nin,nout):\n",
    "        super(Net,self).__init__()\n",
    "        self.sigmoid = nn.ReLU()\n",
    "        self.Dense1 = nn.Linear(nin,80)\n",
    "        self.Dense2 = nn.Linear(80,nout)\n",
    "        self.dropout = nn.Dropout(p=0.0125)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # layer 1\n",
    "        x = self.sigmoid(self.Dense1(x))\n",
    "        x = self.dropout(x)\n",
    "        # layer 2\n",
    "        out = self.Dense2(x)\n",
    "        return out\n",
    "\n",
    "# Initialize network\n",
    "model = Net(nin=nin, nout=nout)\n",
    "\n",
    "# Print string representation\n",
    "print(str(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ebb10e6-8ad4-4a00-964b-59fd39e46773",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.view(10000,-1).to(device)\n",
    "y_train = y_train.to(device)\n",
    "\n",
    "train_ds = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "\n",
    "# Create a training/test data loader from datasets\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=50, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "224d12bb-e425-44c5-967e-29e1a23272f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1   Train Loss: 0.741   Train Acc: 79.17   \n",
      "Epoch: 10   Train Loss: 0.154   Train Acc: 95.62   \n",
      "Epoch: 20   Train Loss: 0.065   Train Acc: 98.04   \n",
      "Epoch: 30   Train Loss: 0.027   Train Acc: 99.29   \n",
      "Epoch: 40   Train Loss: 0.020   Train Acc: 99.42   \n",
      "Epoch: 50   Train Loss: 0.014   Train Acc: 99.59   \n",
      "Epoch: 60   Train Loss: 0.018   Train Acc: 99.38   \n",
      "Epoch: 70   Train Loss: 0.009   Train Acc: 99.71   \n",
      "Epoch: 80   Train Loss: 0.008   Train Acc: 99.72   \n",
      "Epoch: 90   Train Loss: 0.011   Train Acc: 99.64   \n",
      "Epoch: 100   Train Loss: 0.004   Train Acc: 99.86   \n",
      "CPU times: user 47.1 s, sys: 5.5 s, total: 52.6 s\n",
      "Wall time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "lr = 1e-3\n",
    "opt = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "a_tr_loss = []\n",
    "a_tr_accuracy = []\n",
    "\n",
    "num_epoch = 100\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    model.train() # put model in training mode\n",
    "    correct = 0 # initialize error counter\n",
    "    total = 0 # initialize total counter\n",
    "    batch_loss_tr = []\n",
    "    # iterate over training set\n",
    "    for train_iter, data in enumerate(train_loader):\n",
    "        x_batch, y_batch = data\n",
    "        y_batch = y_batch.type(torch.long)\n",
    "        out = model(x_batch)\n",
    "        # Compute Loss\n",
    "        loss = criterion(out, y_batch)\n",
    "        batch_loss_tr.append(loss.item())\n",
    "        # Compute gradients using back propagation\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        # Take an optimization 'step'\n",
    "        opt.step()\n",
    "        # Do hard classification: index of largest score\n",
    "        _, predicted = torch.max(out.data, 1)\n",
    "        # Compute number of decision errors\n",
    "        total += y_batch.size(0)\n",
    "        correct += (predicted == y_batch).sum().item()\n",
    "        \n",
    "    a_tr_loss.append(np.mean(batch_loss_tr)) # Compute average loss over epoch\n",
    "    a_tr_accuracy.append(100*correct/total)\n",
    "\n",
    "    if ((epoch+1) % 10 == 0) or (epoch == 0):\n",
    "        print('Epoch: {0:2d}   Train Loss: {1:.3f}   '.format(epoch+1, a_tr_loss[epoch])\n",
    "          +'Train Acc: {0:.2f}   '.format(a_tr_accuracy[epoch]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db60fc77-89d7-4033-ab89-6032a98485ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:  0.956\n"
     ]
    }
   ],
   "source": [
    "# compute the training accuracy\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    predict = model(x_test.to(device)).cpu().detach().numpy().argmax(axis=1)\n",
    "acc = np.mean(predict==y_test.numpy())\n",
    "print('training accuracy: ',acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6887fa16-a6db-4bf9-a797-e13d4b7e90ca",
   "metadata": {},
   "source": [
    "## Export as CoreML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0541ca9-3cfd-487c-9c0e-553c1d2af102",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "When both 'convert_to' and 'minimum_deployment_target' not specified, 'convert_to' is set to \"mlprogram\" and 'minimum_deployment_targer' is set to ct.target.iOS15 (which is same as ct.target.macOS12). Note: the model will not run on systems older than iOS15/macOS12/watchOS8/tvOS15. In order to make your model run on older system, please set the 'minimum_deployment_target' to iOS14/iOS13. Details please see the link: https://coremltools.readme.io/docs/unified-conversion-api#target-conversion-formats\n",
      "Converting PyTorch Frontend ==> MIL Ops:  83%|█████████████████████████████████▎      | 5/6 [00:00<00:00, 2847.07 ops/s]\n",
      "Running MIL frontend_pytorch pipeline: 100%|██████████████████████████████████████| 5/5 [00:00<00:00, 13239.60 passes/s]\n",
      "Running MIL default pipeline: 100%|██████████████████████████████████████████████| 71/71 [00:00<00:00, 6827.04 passes/s]\n",
      "Running MIL backend_mlprogram pipeline: 100%|███████████████████████████████████| 12/12 [00:00<00:00, 24244.53 passes/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 182 ms, sys: 41.9 ms, total: 224 ms\n",
      "Wall time: 259 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Then, create an example input tensor\n",
    "example_input = torch.rand(1, 784)  # Adjust size accordingly to your input\n",
    "\n",
    "# Convert your model to TorchScript via tracing\n",
    "traced_model = torch.jit.trace(model.cpu(), example_input)\n",
    "\n",
    "# Now you can convert your TorchScript model to CoreML\n",
    "coreml_model = ct.convert(\n",
    "    traced_model,\n",
    "    inputs=[ct.TensorType(name=\"image\", shape=example_input.shape)],\n",
    "    source='pytorch'\n",
    ")\n",
    "\n",
    "# Save the CoreML model\n",
    "coreml_model.save('MNIST.mlpackage')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
