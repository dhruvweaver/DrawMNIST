{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61449e58-ad43-40e0-8e09-65cae2cbd074",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scikit-learn version 1.3.0 is not supported. Minimum required version: 0.17. Maximum required version: 1.1.2. Disabling scikit-learn conversion API.\n"
     ]
    }
   ],
   "source": [
    "import time, torch, numpy as np\n",
    "import matplotlib as mpl, matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch import tensor ,nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import coremltools as ct\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed6d61a-2973-46bb-b076-ba25e37b20ce",
   "metadata": {},
   "source": [
    "### Configure GPU acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fa28d33-90a9-43e0-b039-b58887ea459f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "# cuda: NVIDIA GPUs, mps: Metal Performance Shaders (Apple M GPUs), cpu: generic CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37862f4d-ed65-4196-8591-92ae3d028d0b",
   "metadata": {},
   "source": [
    "### Import MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69999be2-7021-4f2c-aa6b-ea4d1c9662e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('./MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=50000, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.MNIST('./MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=10000, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a294a219-9d80-4234-9ee4-4d48e69146b6",
   "metadata": {},
   "source": [
    "#### Create tensors for training and testing from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8a66505-4fb9-40da-a421-70a58e372fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 1, 28, 28])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train = next(iter(trainloader))\n",
    "x_test, y_test = next(iter(testloader))\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3976511e-e81b-43f8-bfca-06e28779ccb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = x_train.view(50000,-1)\n",
    "# x_test = x_test.view(10000,-1)\n",
    "# x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a6e12a5-9e51-4914-80a4-a9c9f7850622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(y_train[500])\n",
    "xsq = x_train.reshape((-1,28,28)).to(torch.device(\"cpu\"))\n",
    "_ = plt.imshow(xsq[500].view(28,28), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31df1451-c1bc-46ab-be55-5a0674ddf314",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3aff1b-a366-48eb-9450-2f323a825150",
   "metadata": {},
   "source": [
    "### Configure network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b41d9a9-2293-49f6-9244-8527b5290468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (sigmoid): ReLU()\n",
      "  (Dense1): Linear(in_features=1, out_features=800, bias=True)\n",
      "  (Dense2): Linear(in_features=800, out_features=10, bias=True)\n",
      "  (dropout1): Dropout(p=0.0025, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# construct the model\n",
    "nin = x_train.shape[1]\n",
    "nout = int(np.max(y_train.numpy())+1)\n",
    "\n",
    "# Create Net class\n",
    "# nin: dimension of input data\n",
    "# nout: number of outputs\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,nin,nout):\n",
    "        super(Net,self).__init__()\n",
    "        self.sigmoid = nn.ReLU()\n",
    "        self.Dense1 = nn.Linear(nin,800)\n",
    "        self.Dense2 = nn.Linear(800, nout)\n",
    "        self.dropout1 = nn.Dropout(p=0.0025)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # flatten image input\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # layer 1\n",
    "        x = self.sigmoid(self.Dense1(x))\n",
    "        x = self.dropout1(x)\n",
    "        # layer 2\n",
    "        out = self.Dense2(x)\n",
    "        return out\n",
    "\n",
    "# Initialize network\n",
    "model = Net(nin=nin, nout=nout)\n",
    "\n",
    "# Print string representation\n",
    "print(str(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e443a66-c454-44e8-baba-7575eaa288f8",
   "metadata": {},
   "source": [
    "### Prepare dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ebb10e6-8ad4-4a00-964b-59fd39e46773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = x_train.view(50000,-1).to(device)\n",
    "x_train = x_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "\n",
    "train_ds = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "\n",
    "# Create a training/test data loader from datasets\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd543b1-15bf-4497-b067-306f030c1bd6",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8361f147-9ea7-4b8f-b107-ea49c9081856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# model.to(device)\n",
    "\n",
    "# lr = 1e-3\n",
    "# opt = optim.Adam(model.parameters(), lr=lr)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# a_tr_loss = []\n",
    "# a_tr_accuracy = []\n",
    "\n",
    "# num_epoch = 100\n",
    "\n",
    "# for epoch in range(num_epoch):\n",
    "#     model.train() # put model in training mode\n",
    "#     correct = 0 # initialize error counter\n",
    "#     total = 0 # initialize total counter\n",
    "#     batch_loss_tr = []\n",
    "#     # iterate over training set\n",
    "#     for train_iter, data in enumerate(train_loader):\n",
    "#         x_batch, y_batch = data\n",
    "#         y_batch = y_batch.type(torch.long)\n",
    "#         out = model(x_batch)\n",
    "#         # Compute Loss\n",
    "#         loss = criterion(out, y_batch)\n",
    "#         batch_loss_tr.append(loss.item())\n",
    "#         # Compute gradients using back propagation\n",
    "#         opt.zero_grad()\n",
    "#         loss.backward()\n",
    "#         # Take an optimization 'step'\n",
    "#         opt.step()\n",
    "#         # Do hard classification: index of largest score\n",
    "#         _, predicted = torch.max(out.data, 1)\n",
    "#         # Compute number of decision errors\n",
    "#         total += y_batch.size(0)\n",
    "#         correct += (predicted == y_batch).sum().item()\n",
    "        \n",
    "#     a_tr_loss.append(np.mean(batch_loss_tr)) # Compute average loss over epoch\n",
    "#     a_tr_accuracy.append(100*correct/total)\n",
    "\n",
    "#     if ((epoch+1) % 10 == 0) or (epoch == 0):\n",
    "#         print('\\nEpoch: {0:2d}   Train Loss: {1:.3f}   '.format(epoch+1, a_tr_loss[epoch])\n",
    "#           +'Train Acc: {0:.2f}   '.format(a_tr_accuracy[epoch]))\n",
    "#     elif ((epoch+1) % 1 == 0):\n",
    "#         print('=', end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3756ff0-4af9-4c08-8d98-88ec2f6dd79a",
   "metadata": {},
   "source": [
    "#### Evaluate model accuracy on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db60fc77-89d7-4033-ab89-6032a98485ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # compute the training accuracy\n",
    "# with torch.no_grad():\n",
    "#     predict = model(x_test.to(device)).cpu().detach().numpy().argmax(axis=1)\n",
    "# acc = np.mean(predict==y_test.numpy())\n",
    "# print('training accuracy: ',acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd67b06-2acb-4efa-b4f7-9d7e66be7528",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16903b00-3435-4a20-9319-1ccd2fd6186f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNet(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=9216, out_features=800, bias=True)\n",
      "  (fc2): Linear(in_features=800, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# construct the model\n",
    "nin = x_train.shape[1]\n",
    "nout = int(np.max(y_train.cpu().numpy())+1)\n",
    "\n",
    "# Create Net class\n",
    "# nin: dimension of input data\n",
    "# nout: number of outputs\n",
    "class CNNet(nn.Module):\n",
    "    def __init__(self,nin,nout):\n",
    "        super(CNNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 800)\n",
    "        self.fc2 = nn.Linear(800, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "# Initialize network\n",
    "cnn_model = CNNet(nin=nin, nout=nout)\n",
    "\n",
    "# Print string representation\n",
    "print(str(cnn_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85773314-deec-4c63-b524-7c22193d7ac0",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ded9e76-449d-497a-b1f4-be691234125c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  1   Train Loss: 0.369   Train Acc: 91.46   \n",
      "========\n",
      "Epoch: 10   Train Loss: 0.110   Train Acc: 96.89   \n",
      "=========\n",
      "Epoch: 20   Train Loss: 0.105   Train Acc: 97.13   \n",
      "=========\n",
      "Epoch: 30   Train Loss: 0.104   Train Acc: 97.29   \n",
      "=========\n",
      "Epoch: 40   Train Loss: 0.103   Train Acc: 97.25   \n",
      "=========\n",
      "Epoch: 50   Train Loss: 0.108   Train Acc: 97.38   \n",
      "CPU times: user 4min 2s, sys: 21.2 s, total: 4min 23s\n",
      "Wall time: 7min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cnn_model.to(device)\n",
    "\n",
    "lr = 1e-2\n",
    "opt = optim.Adam(cnn_model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "a_tr_loss = []\n",
    "a_tr_accuracy = []\n",
    "\n",
    "num_epoch = 100\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    cnn_model.train() # put model in training mode\n",
    "    correct = 0 # initialize error counter\n",
    "    total = 0 # initialize total counter\n",
    "    batch_loss_tr = []\n",
    "    # iterate over training set\n",
    "    for train_iter, data in enumerate(train_loader):\n",
    "        x_batch, y_batch = data\n",
    "        y_batch = y_batch.type(torch.long)\n",
    "        out = cnn_model(x_batch)\n",
    "        # Compute Loss\n",
    "        loss = criterion(out, y_batch)\n",
    "        batch_loss_tr.append(loss.item())\n",
    "        # Compute gradients using back propagation\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        # Take an optimization 'step'\n",
    "        opt.step()\n",
    "        # Do hard classification: index of largest score\n",
    "        _, predicted = torch.max(out.data, 1)\n",
    "        # Compute number of decision errors\n",
    "        total += y_batch.size(0)\n",
    "        correct += (predicted == y_batch).sum().item()\n",
    "        \n",
    "    a_tr_loss.append(np.mean(batch_loss_tr)) # Compute average loss over epoch\n",
    "    a_tr_accuracy.append(100*correct/total)\n",
    "\n",
    "    if ((epoch+1) % 10 == 0) or (epoch == 0):\n",
    "        print('\\nEpoch: {0:2d}   Train Loss: {1:.3f}   '.format(epoch+1, a_tr_loss[epoch])\n",
    "          +'Train Acc: {0:.2f}   '.format(a_tr_accuracy[epoch]))\n",
    "    elif ((epoch+1) % 1 == 0):\n",
    "        print('=', end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5218831c-12c7-4568-b0db-14354c2b83fc",
   "metadata": {},
   "source": [
    "#### Evaluate model accuracy on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8a367a8-4b3c-409c-aa02-05eddd0769eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:  0.9659\n"
     ]
    }
   ],
   "source": [
    "# compute the training accuracy\n",
    "with torch.no_grad():\n",
    "    predict = cnn_model(x_test.to(device)).cpu().detach().numpy().argmax(axis=1)\n",
    "acc = np.mean(predict==y_test.numpy())\n",
    "print('training accuracy: ',acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6887fa16-a6db-4bf9-a797-e13d4b7e90ca",
   "metadata": {},
   "source": [
    "## Export as Core ML\n",
    "In order to use this model in an Xcode app, it must be converted to Core ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74086b41-57ec-4f51-8b32-560b3b290255",
   "metadata": {},
   "source": [
    "#### Wrap trained model with softmax on output\n",
    "After the model is trained, we want to add softmax to the output.\n",
    "This is so that the CoreML model can output probabilities which can be used later by an app, for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2af30e4-3b57-4469-b0a9-3b168a9e90af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxWrapper(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(SoftmaxWrapper, self).__init__()\n",
    "        self.model = model\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        logits = self.model(input)\n",
    "        probabilities = self.softmax(logits)\n",
    "        return probabilities\n",
    "\n",
    "# wrap trained model\n",
    "model_with_softmax = SoftmaxWrapper(cnn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541365bd-b589-436d-95ad-6f32f91b5709",
   "metadata": {},
   "source": [
    "### Convert to Core ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0541ca9-3cfd-487c-9c0e-553c1d2af102",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting PyTorch Frontend ==> MIL Ops:  97%|████████████████████████████████████▉ | 35/36 [00:00<00:00, 7927.46 ops/s]\n",
      "Running MIL frontend_pytorch pipeline: 100%|███████████████████████████████████████| 5/5 [00:00<00:00, 7836.89 passes/s]\n",
      "Running MIL default pipeline:   0%|                                                         | 0/71 [00:00<?, ? passes/s]/opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:267: UserWarning: Output, '50', of the source model, has been renamed to 'var_50' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "Running MIL default pipeline: 100%|███████████████████████████████████████████████| 71/71 [00:00<00:00, 398.68 passes/s]\n",
      "Running MIL backend_mlprogram pipeline: 100%|███████████████████████████████████| 12/12 [00:00<00:00, 10307.53 passes/s]\n"
     ]
    }
   ],
   "source": [
    "model_with_softmax.eval()\n",
    "\n",
    "# create an example input tensor\n",
    "example_input = torch.rand(1, 1, 28, 28)\n",
    "\n",
    "# convert model to TorchScript via tracing\n",
    "traced_model = torch.jit.trace(model_with_softmax.cpu(), example_input)\n",
    "\n",
    "# convert TorchScript model to CoreML\n",
    "coreml_model = ct.convert(\n",
    "    traced_model,\n",
    "    convert_to=\"mlprogram\",\n",
    "    inputs=[ct.ImageType(name=\"Input\", \n",
    "                         shape=(1, 1, 28, 28), \n",
    "                         color_layout=ct.colorlayout.GRAYSCALE, \n",
    "                         bias=0.5\n",
    "                        )],\n",
    "    classifier_config = ct.ClassifierConfig(class_labels=list(range(10)), predicted_feature_name=\"Prediction\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6393de75-e0f7-4799-9b3c-ab2c0f4c3de2",
   "metadata": {},
   "source": [
    "#### Add metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fee2a16d-35d0-4ddf-8627-c09e617523b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "coreml_model.input_description[\"Input\"] = \"Input image containing a white number on a black background\"\n",
    "coreml_model.output_description[\"Prediction\"] = \"Predicted number\"\n",
    "\n",
    "coreml_model.author = \"Dhruv Weaver\"\n",
    "\n",
    "# coreml_model.license = \"\"\n",
    "\n",
    "coreml_model.short_description = \"Classifies written numbers using a model trained on MNIST dataset\"\n",
    "\n",
    "# set the preview type\n",
    "coreml_model.user_defined_metadata[\"com.apple.coreml.model.preview.type\"] = \"imageClassifier\"\n",
    "\n",
    "coreml_model.version = \"0.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decff053-e688-42f1-ba41-41bc456151ee",
   "metadata": {},
   "source": [
    "#### Test converted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab88fe7e-176c-4211-8183-7aadeef24eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABqUlEQVR4nMWRMWsUURRGz3vvvtk3Mzu760pAEZWAYpqQdjsbsRDRyiKgWCg2tgq2tnbaaeMPsLSKoIVYCLEQSWOjIEEEAytmJu64M3Mtdty4+gP8ynv4LpdzoY3FeQJGwILj7wSsQBQIhmSBeAtAFoCD4Z8iPhkcuf/sKgLRIjEpAK/0HRkEv0gjAukh3f3SkbSDnR3ZxilTitWd7pavipLFpgdv/WOtL5BAPB8GB5B43ANVPe+xSHtIBHQ8COb6WPPmnMHOt2YZQCy2d2NHX6peEnxrSOJdGI7d6ujkmZXvt59uaVSh6FyNhbObtRaPThN0fAUsMpfruxCfWl6GdK2pbuF+ExFXTqfim/culqr4uH10KDJtoa1Kb6nKkiaveuxtV2VV1uwbUmyD7cCE6Id5ExtSGgAbMVURus2Evqfuu71JQ9GurWf93CwdXzoxGtx5Ozy88nDduH1FjuGxe7nm+VfVn58/6N2ZBUHVaL1285ql/BZebyaTA/LpeVsM0DFcVi2eXMR6On8+UgBh9GJjHQP06MdkMJjR1BMJGUKMhwToz/r/Jb8AA2yAuz34d88AAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 2\n",
      "Probabilites:\n",
      "{'var_50': array([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32), 'Prediction': 2, 'Prediction_probs': {0: 0.0, 9: 0.0, 5: 0.0, 1: 0.0, 6: 0.0, 2: 1.0, 7: 0.0, 3: 0.0, 8: 0.0, 4: 0.0}}\n"
     ]
    }
   ],
   "source": [
    "img = Image.open(\"image.jpg\")\n",
    "display(img)\n",
    "prediction = coreml_model.predict({\"Input\" : img})['Prediction']\n",
    "print(f'Prediction: {prediction}')\n",
    "print('Probabilites:')\n",
    "# print(coreml_model.predict({\"Input\" : img})['Prediction_probs'])\n",
    "print(coreml_model.predict({\"Input\" : img}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a51327-ee81-4b70-86be-3aa3650e9543",
   "metadata": {},
   "source": [
    "### Export model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a99a37f-17a4-4c7e-8455-35d997029df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the CoreML model\n",
    "coreml_model.save('MNIST_CNN.mlpackage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c00d8ce-f2fd-49f5-a16b-1eeb83a32545",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
