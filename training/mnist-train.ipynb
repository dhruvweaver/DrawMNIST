{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61449e58-ad43-40e0-8e09-65cae2cbd074",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scikit-learn version 1.3.0 is not supported. Minimum required version: 0.17. Maximum required version: 1.1.2. Disabling scikit-learn conversion API.\n"
     ]
    }
   ],
   "source": [
    "import torch, matplotlib as mpl\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch import tensor\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import coremltools as ct\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed6d61a-2973-46bb-b076-ba25e37b20ce",
   "metadata": {},
   "source": [
    "### Configure GPU acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fa28d33-90a9-43e0-b039-b58887ea459f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "# cuda: NVIDIA GPUs, mps: Metal Performance Shaders (Apple M GPUs), cpu: generic CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37862f4d-ed65-4196-8591-92ae3d028d0b",
   "metadata": {},
   "source": [
    "### Import MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69999be2-7021-4f2c-aa6b-ea4d1c9662e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('./MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=50000, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.MNIST('./MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=10000, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a294a219-9d80-4234-9ee4-4d48e69146b6",
   "metadata": {},
   "source": [
    "#### Create tensors for training and testing from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8a66505-4fb9-40da-a421-70a58e372fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 1, 28, 28])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train = next(iter(trainloader))\n",
    "x_test, y_test = next(iter(testloader))\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3976511e-e81b-43f8-bfca-06e28779ccb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 784])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = x_train.view(50000,-1)\n",
    "x_test = x_test.view(10000,-1)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a6e12a5-9e51-4914-80a4-a9c9f7850622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(y_train[500])\n",
    "xsq = x_train.reshape((-1,28,28)).to(torch.device(\"cpu\"))\n",
    "_ = plt.imshow(xsq[500].view(28,28), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31df1451-c1bc-46ab-be55-5a0674ddf314",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3aff1b-a366-48eb-9450-2f323a825150",
   "metadata": {},
   "source": [
    "### Configure network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b41d9a9-2293-49f6-9244-8527b5290468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (sigmoid): ReLU()\n",
      "  (Dense1): Linear(in_features=784, out_features=800, bias=True)\n",
      "  (Dense2): Linear(in_features=800, out_features=80, bias=True)\n",
      "  (Dense3): Linear(in_features=80, out_features=10, bias=True)\n",
      "  (dropout1): Dropout(p=0.00125, inplace=False)\n",
      "  (dropout2): Dropout(p=0.0125, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# construct the model\n",
    "nin = x_train.shape[1]\n",
    "nout = int(np.max(y_train.numpy())+1)\n",
    "\n",
    "# Create Net class\n",
    "# nin: dimension of input data\n",
    "# nout: number of outputs\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,nin,nout):\n",
    "        super(Net,self).__init__()\n",
    "        self.sigmoid = nn.ReLU()\n",
    "        self.Dense1 = nn.Linear(nin,800)\n",
    "        self.Dense2 = nn.Linear(800, 80)\n",
    "        self.Dense3 = nn.Linear(80,nout)\n",
    "        self.dropout1 = nn.Dropout(p=0.00125)\n",
    "        self.dropout2 = nn.Dropout(p=0.0125)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # flatten image input\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # layer 1\n",
    "        x = self.sigmoid(self.Dense1(x))\n",
    "        x = self.dropout1(x)\n",
    "        # layer 2\n",
    "        x = self.sigmoid(self.Dense2(x))\n",
    "        x = self.dropout2(x)\n",
    "        # layer 3\n",
    "        out = self.Dense3(x)\n",
    "        return out\n",
    "\n",
    "# Initialize network\n",
    "model = Net(nin=nin, nout=nout)\n",
    "\n",
    "# Print string representation\n",
    "print(str(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ebb10e6-8ad4-4a00-964b-59fd39e46773",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.view(50000,-1).to(device)\n",
    "y_train = y_train.to(device)\n",
    "\n",
    "train_ds = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "\n",
    "# Create a training/test data loader from datasets\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "224d12bb-e425-44c5-967e-29e1a23272f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  1   Train Loss: 0.392   Train Acc: 88.12   \n",
      "========\n",
      "Epoch: 10   Train Loss: 0.043   Train Acc: 98.53   \n",
      "=========\n",
      "Epoch: 20   Train Loss: 0.023   Train Acc: 99.18   \n",
      "=========\n",
      "Epoch: 30   Train Loss: 0.015   Train Acc: 99.47   \n",
      "=========\n",
      "Epoch: 40   Train Loss: 0.014   Train Acc: 99.54   \n",
      "=========\n",
      "Epoch: 50   Train Loss: 0.017   Train Acc: 99.52   \n",
      "CPU times: user 2min 30s, sys: 14.7 s, total: 2min 44s\n",
      "Wall time: 4min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "lr = 1e-3\n",
    "opt = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "a_tr_loss = []\n",
    "a_tr_accuracy = []\n",
    "\n",
    "num_epoch = 50\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    model.train() # put model in training mode\n",
    "    correct = 0 # initialize error counter\n",
    "    total = 0 # initialize total counter\n",
    "    batch_loss_tr = []\n",
    "    # iterate over training set\n",
    "    for train_iter, data in enumerate(train_loader):\n",
    "        x_batch, y_batch = data\n",
    "        y_batch = y_batch.type(torch.long)\n",
    "        out = model(x_batch)\n",
    "        # Compute Loss\n",
    "        loss = criterion(out, y_batch)\n",
    "        batch_loss_tr.append(loss.item())\n",
    "        # Compute gradients using back propagation\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        # Take an optimization 'step'\n",
    "        opt.step()\n",
    "        # Do hard classification: index of largest score\n",
    "        _, predicted = torch.max(out.data, 1)\n",
    "        # Compute number of decision errors\n",
    "        total += y_batch.size(0)\n",
    "        correct += (predicted == y_batch).sum().item()\n",
    "        \n",
    "    a_tr_loss.append(np.mean(batch_loss_tr)) # Compute average loss over epoch\n",
    "    a_tr_accuracy.append(100*correct/total)\n",
    "\n",
    "    if ((epoch+1) % 10 == 0) or (epoch == 0):\n",
    "        print('\\nEpoch: {0:2d}   Train Loss: {1:.3f}   '.format(epoch+1, a_tr_loss[epoch])\n",
    "          +'Train Acc: {0:.2f}   '.format(a_tr_accuracy[epoch]))\n",
    "    elif ((epoch+1) % 1 == 0):\n",
    "        print('=', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db60fc77-89d7-4033-ab89-6032a98485ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:  0.9799\n"
     ]
    }
   ],
   "source": [
    "# compute the training accuracy\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    predict = model(x_test.to(device)).cpu().detach().numpy().argmax(axis=1)\n",
    "acc = np.mean(predict==y_test.numpy())\n",
    "print('training accuracy: ',acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6887fa16-a6db-4bf9-a797-e13d4b7e90ca",
   "metadata": {},
   "source": [
    "## Export as CoreML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74086b41-57ec-4f51-8b32-560b3b290255",
   "metadata": {},
   "source": [
    "#### Wrap trained model with softmax on output\n",
    "After the model is trained, we want to add softmax to the output.\n",
    "This is so that the CoreML model can output probabilities which can be used later by an app, for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2af30e4-3b57-4469-b0a9-3b168a9e90af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxWrapper(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(SoftmaxWrapper, self).__init__()\n",
    "        self.model = model\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        logits = self.model(input)\n",
    "        probabilities = self.softmax(logits)\n",
    "        return probabilities\n",
    "\n",
    "# wrap trained model\n",
    "model_with_softmax = SoftmaxWrapper(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0541ca9-3cfd-487c-9c0e-553c1d2af102",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model is not in eval mode. Consider calling '.eval()' on your model prior to conversion\n",
      "Converting PyTorch Frontend ==> MIL Ops:  94%|███████████████████████████████████▉  | 17/18 [00:00<00:00, 7413.51 ops/s]\n",
      "Running MIL frontend_pytorch pipeline: 100%|███████████████████████████████████████| 5/5 [00:00<00:00, 9650.95 passes/s]\n",
      "Running MIL default pipeline:   0%|                                                         | 0/71 [00:00<?, ? passes/s]/opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:267: UserWarning: Output, '29', of the source model, has been renamed to 'var_29' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "Running MIL default pipeline: 100%|██████████████████████████████████████████████| 71/71 [00:00<00:00, 2855.40 passes/s]\n",
      "Running MIL backend_mlprogram pipeline: 100%|███████████████████████████████████| 12/12 [00:00<00:00, 14908.66 passes/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 218 ms, sys: 39.5 ms, total: 258 ms\n",
      "Wall time: 273 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# create an example input tensor\n",
    "example_input = torch.rand(1, 1, 28, 28)\n",
    "\n",
    "# convert model to TorchScript via tracing\n",
    "traced_model = torch.jit.trace(model_with_softmax.cpu(), example_input)\n",
    "\n",
    "# convert TorchScript model to CoreML\n",
    "coreml_model = ct.convert(\n",
    "    traced_model,\n",
    "    convert_to=\"mlprogram\",\n",
    "    inputs=[ct.ImageType(name=\"Input\", \n",
    "                         shape=(1, 1, 28, 28), \n",
    "                         color_layout=ct.colorlayout.GRAYSCALE, \n",
    "                         bias=0.5\n",
    "                        )],\n",
    "    classifier_config = ct.ClassifierConfig(class_labels=list(range(10)), predicted_feature_name=\"Prediction\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fee2a16d-35d0-4ddf-8627-c09e617523b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "coreml_model.input_description[\"Input\"] = \"Input image containing a white number on a black background\"\n",
    "coreml_model.output_description[\"Prediction\"] = \"Predicted number\"\n",
    "\n",
    "coreml_model.author = \"Dhruv Weaver\"\n",
    "\n",
    "# coreml_model.license = \"\"\n",
    "\n",
    "coreml_model.short_description = \"Classifies written numbers using a model trained on MNIST dataset\"\n",
    "\n",
    "# set the preview type\n",
    "coreml_model.user_defined_metadata[\"com.apple.coreml.model.preview.type\"] = \"imageClassifier\"\n",
    "\n",
    "coreml_model.version = \"0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab88fe7e-176c-4211-8183-7aadeef24eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+tjwzo51/xPpukDfi7uEiYp1VSRuPQ9Bk/hVrxroVr4Z8Y6lo1ncm5gtZAiytjd90Eg44yCSD9K52rFsLdrmIXTyRwFh5jRKGYL3IBIBP4ivV/Avifwn4Z8TaXbeGrS9uby/uoba41HVAq+TEzgMsaITgkdya434moY/iZ4hBxk3rng568/1rkqv6RZRajq9rZ3F5FZwzyqj3M33IgT94+1ehzx/DDwre2/2bUtd1fUrR1kF1ZCJIDIpBGN4PH/fQrD8Ya74V16XUNQsNN1RNVvbgTNLc3CGOPJJYBVA6+/TFcTRRRRX/2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABzklEQVR4Ab1SPYsUQRB93V0907OzX64cKKJyoHjJcelmJmIgotEFBycGiompgqmpmWaa+AMMjRQ0EAPhDEQuMVGQQwQPVryZc8fpmbJ6Z3Zh/QFWQ3dVv67H69cNtKFhLBwUARow8+3F6qAFihycQmexGxIr5yV6TqajYfonbGd44uHL6wjty5BKZ/Vb/oge4OwyGomc9BgffI8pjYOombLmjGGUyNf3u7vW5wWWO6Wy2j7l6kpQmjQdsulmt+pYmEfMfNkKp2gKoYKwWI4Q1M0JZ/UlJeCctSfihId0/9Y+v2HeJIEahyg5AEYTsz4+e2Ht193nuxx5sIwmrBbZF3cqzp+ch+PJtXAFWphru0J7bnUVSDdqfwdmjhCZoizJ1p9MQj7/sndyRFS2pNoXYrkvCtSZ7+Nwzxe+qFpzgk0MXUPHwBTRb/U+UUhRh2YdoWQidOspBhbVwBxOa+QNrxaKQJKpldMrZ8bDex9Gx9ceb6lWU7DIYHTqQcZZ9oP5z7fPfL9xgcCsuNq4fUOj+One7XSmR+jrq7ZRfkSssM2cP7sKbSG6Wq2yBv8J49cvtqAk7WOQhK8wlFwitYhIapJHlMcI327Q9M/g/z39BQNsgLu6sa8dAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 3\n",
      "Probabilites:\n",
      "{'var_29': array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]], dtype=float32), 'Prediction': 3, 'Prediction_probs': {0: 0.0, 9: 0.0, 5: 0.0, 1: 0.0, 6: 0.0, 2: 0.0, 7: 0.0, 3: 1.0, 8: 0.0, 4: 0.0}}\n"
     ]
    }
   ],
   "source": [
    "img = Image.open(\"image.jpg\")\n",
    "display(img)\n",
    "prediction = coreml_model.predict({\"Input\" : img})['Prediction']\n",
    "print(f'Prediction: {prediction}')\n",
    "print('Probabilites:')\n",
    "# print(coreml_model.predict({\"Input\" : img})['Prediction_probs'])\n",
    "print(coreml_model.predict({\"Input\" : img}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a99a37f-17a4-4c7e-8455-35d997029df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the CoreML model\n",
    "coreml_model.save('MNIST.mlpackage')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
